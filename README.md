# üìò Docu-Mentor Backend

This is the backend service for **Docu-Mentor**, powered by **FastAPI**, **LangChain**, and **HuggingFace models**.  
It provides a Retrieval-Augmented Generation (RAG) pipeline where questions are answered based on a local knowledge base (`knowledge.txt`).  

---

## ‚öôÔ∏è Setup Instructions

### 1Ô∏è‚É£ Clone the repository
```bash
git clone https://github.com/your-username/docu-mentor.git
cd docu-mentor/backend
```

### 2Ô∏è‚É£ Create and configure `.env`
Inside `backend/.env` add:
```env
HUGGINGFACEHUB_API_TOKEN=your_hf_api_token_here
```

üëâ Get a free token from [HuggingFace](https://huggingface.co/settings/tokens).

---

## üöÄ Run the Project

### ‚ñ∂Ô∏è Run with Docker Compose
Build and start the container:
```bash
docker-compose up --build
```

Stop the container:
```bash
docker-compose down
```

### ‚ñ∂Ô∏è Run Locally (without Docker)
```bash
python -m venv venv
source venv/bin/activate   # On Linux/Mac
venv\Scripts\activate      # On Windows

pip install -r requirements.txt
uvicorn src.server:app --reload
```

---

## üì° API Endpoints

### 1Ô∏è‚É£ Health Check
```http
GET /ping
```
**Response:**
```json
{ "status": "ok" }
```

### 2Ô∏è‚É£ Ask Question
```http
POST /ask
```
**Body:**
```json
{
  "question": "What is Innovatech?"
}
```

**Response:**
```json
{
  "answer": "Innovatech is ..."
}
```

---

## üõ†Ô∏è Tech Stack
- **FastAPI** - API framework  
- **LangChain** - RAG pipeline  
- **HuggingFace** - Models & embeddings  
- **FAISS** - Vector storage  
- **Docker** - Containerization  

---
